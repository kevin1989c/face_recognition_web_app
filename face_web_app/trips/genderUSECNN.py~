#!/usr/bin/python
# -*- coding: UTF-8 -*-
import os
import sys
import cPickle
import csv
import numpy
from PIL import Image
import cv2
import theano
import theano.tensor as T
from theano.tensor.signal import pool
from theano.tensor.nnet import conv


#读取之前保存的训练参数
#layer0_params~layer3_params都是包含W和b的,layer*_params[0]是W，layer*_params[1]是b
def detect(pic):
    image = numpy.array(pic.convert('L'), 'uint8')
    cascadePath = "/usr/local/opencv/data/haarcascades/haarcascade_frontalface_default.xml"
    faceCascade = cv2.CascadeClassifier(cascadePath)
    faces = faceCascade.detectMultiScale(image)
    for (x, y, w, h) in faces:
            pic=Image.fromarray(image[y: y + h, x: x + w],'L')
            repic=pic.resize((50,50),Image.ANTIALIAS )
    return repic

def load_params(train_i):
    fr=open('/home/kevin/facerc/pyface/FACERE_TEST/gender classfication/params_train_i_154.pkl','rb')
    layer0_params=cPickle.load(fr)
    layer1_params=cPickle.load(fr)
    layer2_params=cPickle.load(fr)
    layer3_params=cPickle.load(fr)
    fr.close()
    return layer0_params,layer1_params,layer2_params,layer3_params

#读取图像，返回numpy.array类型的人脸数据以及对应的label



def load_data(file_path, img_h, img_w):
     faces=numpy.zeros((1,img_h*img_w))   
     i=0
     img1=Image.open(file_path)
     img2=img1.convert('L')
     img=detect(img2)
     img_ndarray=numpy.asarray(img,dtype='float64')/256
     faces[i]=numpy.ndarray.flatten(img_ndarray[:])
  
     return faces

"""
train_CNN_olivettifaces中的LeNetConvPoolLayer、HiddenLayer、LogisticRegression是随机初始化的
下面将它们定义为可以用参数来初始化的版本
"""
class LogisticRegression(object):
    def __init__(self, input, params_W, params_b, n_in, n_out):
        self.W = params_W
        self.b = params_b
        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)
        self.y_pred = T.argmax(self.p_y_given_x, axis=1)
        self.params = [self.W, self.b]

    def negative_log_likelihood(self, y):
        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])

    def errors(self, y):
        if y.ndim != self.y_pred.ndim:
            raise TypeError(
                'y should have the same shape as self.y_pred',
                ('y', y.type, 'y_pred', self.y_pred.type)
            )
        if y.dtype.startswith('int'):
            return T.mean(T.neq(self.y_pred, y))
        else:
            raise NotImplementedError()


class HiddenLayer(object):
    def __init__(self, input, params_W,params_b, n_in, n_out,
                 activation=T.tanh):
        self.input = input
        self.W = params_W
        self.b = params_b

        lin_output = T.dot(input, self.W) + self.b
        self.output = (
            lin_output if activation is None
            else activation(lin_output)
        )
        self.params = [self.W, self.b]

	
#卷积+采样层（conv+maxpooling）
class LeNetConvPoolLayer(object):
    def __init__ (self, input, filter_w, filter_h, filter_num, img_w, img_h, input_feature,batch_size, poolsize,params_W,params_b):

        self.input = input
        self.W = params_W
        self.b = params_b
        # 卷积
        conv_out = conv.conv2d(
            input=input,
            filters=self.W,
            filter_shape=(filter_num, input_feature, filter_h, filter_w),
            image_shape=(batch_size,input_feature,img_h,img_w)
        )
        # 子采样
        pooled_out = pool.pool_2d(
            input=conv_out,
            ds=poolsize,
            ignore_border=True
        )

        self.output = T.tanh(pooled_out + self.b.dimshuffle('x', 0, 'x', 'x'))
        self.params = [self.W, self.b]



"""
用之前保存下来的参数初始化CNN，就得到了一个训练好的CNN模型，然后使用这个模型来测图像
注意：n_kerns跟之前训练的模型要保持一致。dataset是你要测试的图像的路径，params_file是之前训练时保存的参数文件的路径
"""
def use_CNN(train_i,file_path,filter_num1, filter_num2,filter_h,filter_w,img_h,img_w,poolsize,input_feature,total_image_num,person_num, count_incorrect=0.0): 
    
   
    faces=load_data(file_path, img_h, img_w)


  
    #读入参数
    layer0_params,layer1_params,layer2_params,layer3_params=load_params(train_i)
    
    x = T.matrix('x')  #用变量x表示输入的人脸数据，作为layer0的输入

    ######################
    #用读进来的参数初始化各层参数W、b
    ######################
    layer0_input = x.reshape((total_image_num, input_feature, img_h, img_w))
    layer0 = LeNetConvPoolLayer(
        input=layer0_input,
        params_W=layer0_params[0],
        params_b=layer0_params[1],
        filter_h=filter_h,        
        filter_w=filter_w, 
        filter_num=filter_num1, 
        img_h=img_h,         
        img_w=img_w, 
        input_feature=input_feature,
        batch_size=total_image_num, 
        poolsize=poolsize
    )
    layer1_input=layer0.output
    layer1_image_h=(img_h-filter_h+1)/2
    layer1_image_w=(img_w-filter_w+1)/2
    layer1 = LeNetConvPoolLayer(
        input=layer1_input,
        params_W=layer1_params[0],
        params_b=layer1_params[1],
        filter_h=filter_h,        
        filter_w=filter_w, 
        filter_num=filter_num2,  
        img_h=layer1_image_h, 
        img_w=layer1_image_w, 
        input_feature=filter_num1,
        batch_size=total_image_num,  
        poolsize=poolsize
    )

    
    layer2_input = layer1.output.flatten(2)
    layer2_image_h=(layer1_image_h-filter_h+1)/2
    layer2_image_w=(layer1_image_w-filter_w+1)/2

    layer2 = HiddenLayer(
        input=layer2_input,
        params_W=layer2_params[0],
        params_b=layer2_params[1],
        n_in=filter_num2 *  layer2_image_h * layer2_image_w,
        n_out=300,      
        activation=T.tanh
    )

    layer3 = LogisticRegression(input=layer2.output, params_W=layer3_params[0],params_b=layer3_params[1],n_in=300, n_out=person_num)  

 
     
    #定义theano.function，让x作为输入，layer3.y_pred（即预测的类别）作为输出
    f = theano.function(
        [x],    #funtion 的输入必须是list，即使只有一个输入
        layer3.y_pred
    )
    
    #预测的类别pred
    pred = f(faces)
    

    #将预测的类别pred与真正类别label对比，输出错分的图像
    return pred[0]
    

def face_dtc(file_path):
       
	pred=use_CNN(train_i=154,
        file_path=file_path,
        filter_num1=15,
        filter_num2=30,
        filter_h=5,
        filter_w=5,
        img_h=50,
        img_w=50,
        poolsize=(2,2),
        total_image_num=1,
        person_num=2,
        input_feature=1)

        return pred
